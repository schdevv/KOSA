#### 2023.04.07

### 1. CNN (Convolutional Neural Network) : 합성곱 신경망 → Convnet(컨브넷)
  #### 0) CNN (Convolutional Neural Network) : 합성곱 신경망 → Convnet(컨브넷)
```
  (1) 기능 : 이미지 학습, 예측
    □ Feature Extraction
      ● convoluation
       - 특징 뽑아내기, Image 개수 증가
      ● pooling 
       - Image 개개의 size를 축소
      ● 이미지의 선처리를 통해 이미지를 학습하고 예측
    □ 학습 (DNN) 

  (2) 실사 Image에 대한 학습 여부
    □ 조건부적으로 Data량이 많아야 효과적으로 학습할 수 있음.
      ● 정밀하게 데이터가 정제되있는 Set이라면 적은 데이터 량으로도 가능하나, 일반적으로는 어려움
    □ Feature의 수가 적어야함
      ● 
    □ 학습의 현실
      ● 결과적으로 충분한 데이터가 있음에도 학습은 잘 진행되지 않음(정확도 86%)
      ● 데이터가 적어지면 model의 학습 효율은 더 좋지 않음(정확도 72%)

  (3) 문제 해결방법
    □ CNN의 구조
      ● Feature Extraction의 Filter를 통해 특징을 뽑아냄.
      ● 양질의 특징을 뽑아낼 수 록 Model의 학습의 효과가 커짐.
      ● 따라서 CNN은 특징과 가중치를 잘 뽑아내는 Filter를 만들어가는 과정임.
```
```

    □ Augmentation(데이터 증식)
      ● ImageDataGenerator 적용 시(정확도 79%)
    □ Transfer Learning(전이학습) 
      ● 만일, 효과적인 Filter가 만들어져있다면? 
      ● Computing Power기업의 Model 중, Feature Extraction 부분을 전이학습으로 재사용해 활용함.
        - Data ImgaeNet : 방대한 Data를 가지고 있는 DataSet  
      ● Google : Inception(convolution: 45개, pooling: 20개)
      ● MS : Google의 Inception의 3배에 달함.
       - ResNet
       - EffientNet
       - VGG
       - MobileNet

```
### 2. Transfer Learning(전이학습) 

```
  (1) PreTrained Network (기 학습 Neural Network)
    □ 예제
      ● 개발환경 : coLab
      ● Model : MS사의 VGG16
      ● VGG 다운로드 : tensorflow.Keras
```
```python
# 전이학습 CNN Model : VGG 16 
from tensorflow.keras.applications import  VGG16

model_base = VGG16(weights='imagenet',
                   include_top=False,
                   input_shape=(150,150,3))

print(model_base.summary())
```
![](./images/2023-04-07-10-32-03.png)
![](./images/2023-04-07-10-32-24.png)
```python
import os
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

base_dir = '/content/drive/MyDrive/[파이썬 실습]/cat_dog_small'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

datagen = ImageDataGenerator(rescale=1/255)
batch_size=20

def extract_feature(directory, sample_count):
    features = np.zeros(shape=(sample_count,4,4,512))
    labels = np.zeros(shape=(sample_count,))
    
    generator = datagen.flow_from_directory(
        directory,
        target_size=(150,150),
        batch_size=batch_size,
        class_mode='binary')

    i = 0

    for x_data_batch, t_data_batch in generator:
        feature_batch = model_base.predict(x_data_batch)
        features[i*batch_size:(i+1)*batch_size] = feature_batch
        labels[i*batch_size:(i+1)*batch_size] = t_data_batch
        
        i += 1
        if i * batch_size >= sample_count:
            break;
    
    return features, labels

train_features, train_labels = extract_feature(train_dir,2000)
validation_features, validation_labels = extract_feature(validation_dir,1000)
test_features, test_labels = extract_feature(test_dir,1000)
```
![](./images/2023-04-07-10-33-07.png)
```python
train_features = np.reshape(train_features, (2000,4 * 4 * 512))
validation_features = np.reshape(validation_features, (1000,4 * 4 * 512))
test_features = np.reshape(test_features, (1000,4 * 4 * 512))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import RMSprop

model = Sequential()
model.add(Dense(256,
                activation='relu',
                input_shape=(4 * 4 * 512,)))
model.add(Dropout(0.5))
model.add(Dense(1,
                activation='sigmoid'))

model.compile(optimizer=RMSprop(learning_rate=2e-5),
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_features,
                    train_labels,
                    epochs=30,
                    batch_size=20,
                    validation_data=(validation_features, validation_labels)) 
```
![](./images/2023-04-07-11-41-06.png)


### 3. Machine Learning(지도)
- 하나의 예측 Model 수학식을 만드는 과정

```
  (1) Regression
    □ Deep Learning(비정형) : 자연어는 정확도가 떨어지니 딥러닝 수행이 필수적임
      ● Vision : 이미지
       - 전이학습
      ● NLP : 자연어
 ```
